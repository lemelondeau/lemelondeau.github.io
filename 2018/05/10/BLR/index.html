<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/duola.jpg?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/duola.jpg?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/duola.jpg?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="algorithms," />










<meta name="description" content="Notes of PRML 1. Linear Basis Function Models1.1 Model FormalisationLinear regression is one of the most basic regression models for  supervised learning. It is a parametric model, that is to say, the">
<meta name="keywords" content="algorithms">
<meta property="og:type" content="article">
<meta property="og:title" content="Bayesian Linear Regression and Gaussian Process">
<meta property="og:url" content="https://lemelondeau.github.io/2018/05/10/BLR/index.html">
<meta property="og:site_name" content="Cool Site">
<meta property="og:description" content="Notes of PRML 1. Linear Basis Function Models1.1 Model FormalisationLinear regression is one of the most basic regression models for  supervised learning. It is a parametric model, that is to say, the">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2018-05-23T06:08:05.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bayesian Linear Regression and Gaussian Process">
<meta name="twitter:description" content="Notes of PRML 1. Linear Basis Function Models1.1 Model FormalisationLinear regression is one of the most basic regression models for  supervised learning. It is a parametric model, that is to say, the">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.3',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://lemelondeau.github.io/2018/05/10/BLR/"/>





  <title>Bayesian Linear Regression and Gaussian Process | Cool Site</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-80781234-1', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?//hm.baidu.com/hm.js?ee75cf111111aa99f8540efa2570970";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cool Site</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://lemelondeau.github.io/2018/05/10/BLR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="lemelondeau">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/duola.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cool Site">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Bayesian Linear Regression and Gaussian Process</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-10T19:48:29+08:00">
                2018-05-10
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/05/10/BLR/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/05/10/BLR/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><strong><em>Notes of PRML</em></strong></p>
<h2 id="1-Linear-Basis-Function-Models"><a href="#1-Linear-Basis-Function-Models" class="headerlink" title="1. Linear Basis Function Models"></a>1. Linear Basis Function Models</h2><h3 id="1-1-Model-Formalisation"><a href="#1-1-Model-Formalisation" class="headerlink" title="1.1 Model Formalisation"></a>1.1 Model Formalisation</h3><p>Linear regression is one of the most basic regression models for  supervised learning. It is a <strong>parametric model</strong>, that is to say, the number of parameters to be determined is fixed. During training, the objective of linear regression is to minimise the difference between real output and predicted output. Or equivalently, to maximise the likelihood function. </p>
<p>The simplest linear model for regression is</p>
<script type="math/tex; mode=display">
y(\mathbf{x},\mathbf{w})=w_0+w_1x_1+...+w_Dx_D=\mathbf{w}^T\mathbf{x}</script><p>where $\mathbf{x}=(x_1, … ,x_D)T$ and $\mathbf{w}=(w_0, w_1, … .w_D)$ which is the parameter. It is clear that the output $y$ is a linear combination of the input variables. The key property of this model is that <strong>it is a linear function of the parameters</strong> [1]. Even if the model have the form</p>
<script type="math/tex; mode=display">
y(\mathbf{x},\mathbf{w})=w_0+w_1x_1^2+...+w_Dx_D^2 ,</script><p>it is still a linear regression model. This property encourages us to extend the model to be more flexible by considering linear combinations of fixed nonlinear functions of the input variables, with the following form</p>
<script type="math/tex; mode=display">
y(\mathbf{x},\mathbf{w})=w_0+\sum _{j=1}^{M-1} w_j\phi_j(\mathbf{x})</script><p>where $\phi_j(\mathbf{x})$ are known as basis functions, $M$ is the number of parameters. Define $\phi_0(\mathbf x)=1$, we get</p>
<script type="math/tex; mode=display">
y(\mathbf{x},\mathbf{w})=\sum_{j=0}^{M-1}w_j\phi_j{\mathbf x}=\mathbf w^T\pmb{\phi}(\mathbf x)</script><p>By using nonlinear basis functions, we allow the function $y(\mathbf{x},\mathbf{w})$ to be a non-linear function of the input vector $\mathbf x$.</p>
<h3 id="1-2-Model-Fitting"><a href="#1-2-Model-Fitting" class="headerlink" title="1.2 Model Fitting"></a>1.2 Model Fitting</h3><p>Given a dataset $\mathcal{D}(\mathbf{X,t})$, usually the observations are noisy. Assume the target variable $t$ is the noisy observation</p>
<script type="math/tex; mode=display">
t=y(\mathbf{x},\mathbf{w})+\epsilon</script><p>where $\epsilon \sim \mathcal N(0, \beta^{-1})$. Thus we can write</p>
<script type="math/tex; mode=display">
p(t|\mathbf x, \mathbf w, \beta)=\mathcal N(t|y(\mathbf{x},\mathbf{w}), \beta^{-1})</script><p><strong>Least Square Method</strong></p>
<p>The squared error is written as</p>
<script type="math/tex; mode=display">
E_D(\mathbf w)= \frac{1}{2}\sum_{n=1}^{N}\{t_n-\mathbf w^T\pmb{\phi}(\mathbf x_n)\}^2</script><p>Take the derivative respect to $\mathbf w$ and make it to be zero, we can get</p>
<script type="math/tex; mode=display">
\mathbf w=(\Phi^T\Phi)^{-1}\Phi^T\mathbf t</script><p><strong>Maximum Likelihood</strong> </p>
<p>For i.i.d variables, the likelihood function of target variables is</p>
<script type="math/tex; mode=display">
p(\mathbf t|\mathbf X, \mathbf w, \beta)=\prod_{n=1}^{N}\mathcal N(t_n|\mathbf w^T\pmb{\phi}(\mathbf x_n), \beta^{-1})</script><p>Taking the logarithm of the likelihood function </p>
<script type="math/tex; mode=display">
\begin{align}
\ln p(\mathbf t|\mathbf w, \beta)&=\sum_{n=1}^{N}\ln \mathcal N(t_n|\mathbf w^T\pmb{\phi}(\mathbf x_n), \beta^{-1})\\
&=\sum_{n=1}^{N}\ln (\frac{\sqrt\beta}{\sqrt{2\pi}}\exp(-(t_n-\mathbf w^T\pmb{\phi}(\mathbf x_n))^2\beta/2))\\
&=\sum_{n=1}^{N}(\frac12\ln\beta-\frac12\ln(2\pi)-\frac12\beta\{t_n-\mathbf w^T\pmb{\phi}(\mathbf x_n)\}^2)\\
&=\frac N2\ln \beta-\frac N2\ln(2\pi)-\beta E_D(\mathbf w)
\end{align}</script><p>Maximising the likelihood is therefore equivalent to minimising the square error.</p>
<h2 id="2-Bayesian-Linear-Regression"><a href="#2-Bayesian-Linear-Regression" class="headerlink" title="2. Bayesian Linear Regression"></a>2. Bayesian Linear Regression</h2><p>Over-fitting is a big issue when using maximum likelihood, Bayesian treatment is considered to avoid this.</p>
<h3 id="2-1-Posterior-Distribution-of-Parameter"><a href="#2-1-Posterior-Distribution-of-Parameter" class="headerlink" title="2.1 Posterior Distribution of Parameter"></a>2.1 Posterior Distribution of Parameter</h3><p>One of the aim of Bayesian linear regression is to get the distribution of parameter $\mathbf w$, which is written as $p(\mathbf w|\mathbf X, \mathbf t)$. This is a posterior distribution. Assume a Gaussian distribution over $\mathbf w$,</p>
<script type="math/tex; mode=display">
p(\mathbf w)=\mathcal N(\mathbf w|\mathbf{m_0},\mathbf{S_0}).</script><p>The likelihood is also easy to get</p>
<script type="math/tex; mode=display">
\begin{align}
p(\mathbf t|\mathbf X, \mathbf w, \beta)&=\prod_{n=1}^{N}\mathcal N(t_n|\mathbf w^T\pmb{\phi}(\mathbf x_n), \beta^{-1})
\\
&=\mathcal N(\mathbf t|\Phi \mathbf w, \beta^{-1}I)
\end{align}</script><p>Apply 2.116 conditional Gaussian we will get</p>
<script type="math/tex; mode=display">
p(\mathbf w|\mathbf X, \mathbf t)=\mathcal N(\mathbf w|\mathbf{m}_N,\mathbf{S}_N).</script><p>where</p>
<script type="math/tex; mode=display">
\mathbf m_N=\mathbf S_N(\mathbf S_0^{-1}\mathbf m_0+\beta\Phi^T\mathbf t)\\
\mathbf S_N^{-1}=\mathbf S_0^{-1}+\beta\Phi^T\Phi</script><p>Now, assign a parameter $\alpha$ to control the prior distribution</p>
<script type="math/tex; mode=display">
p(\mathbf w|\alpha)=\mathcal N(\mathbf w|\mathbf 0, \alpha^{-1}I)</script><p>and the corresponding posterior distribution is given by</p>
<script type="math/tex; mode=display">
\mathbf m_N=\beta\mathbf S_N\Phi^T\mathbf t\\
\mathbf S_N^{-1}=\alpha I+\beta\Phi^T\Phi</script><h3 id="2-2-Predictive-Distribution"><a href="#2-2-Predictive-Distribution" class="headerlink" title="2.2 Predictive Distribution"></a>2.2 Predictive Distribution</h3><p>To make prediction for new values of $\mathbf x$, we need to integrate $\mathbf w$ out. The predictive distribution is given by</p>
<script type="math/tex; mode=display">
p(t|\mathbf x, \mathcal D,\alpha, \beta)=\int p(t|\mathbf x, \mathbf w, \beta)p(\mathbf w|\mathcal D,\alpha, \beta)\text{d}\mathbf w\\
=\int \mathcal N(t|\mathbf w^T\phi (\mathbf x) ,\beta^{-1})\mathcal N(\mathbf w|\mathbf{m}_N,\mathbf{S}_N)\text{d}\mathbf w\\
=\mathcal N(t|\mathbf m_N^T\phi(\mathbf x), \sigma_N^2(\mathbf x))</script><p>where $\sigma_N^2$ is given by (use 2.115 marginal distribution)</p>
<script type="math/tex; mode=display">
\sigma_N^2(\mathbf x)=\frac1\beta+\phi(\mathbf x)^T\mathbf S_N\phi(\mathbf x)</script><h2 id="3-Relation-with-Gaussian-Process"><a href="#3-Relation-with-Gaussian-Process" class="headerlink" title="3. Relation with Gaussian Process"></a>3. Relation with Gaussian Process</h2><p>In the above Bayesian linear regression model, $\alpha$ and $\beta$ govern the predictive distribution. We call $\alpha$ and $\beta$ <strong>hyperparameters</strong>.</p>
<p>The hidden variables is given by</p>
<script type="math/tex; mode=display">
y =y(\mathbf{x},\mathbf{w})=\sum_{j=0}^{M-1}w_j\phi_j{\mathbf x}=\mathbf w^T\pmb{\phi}(\mathbf x)</script><p>$\mathbf y$ is a linear combination of Gaussian distributed variables hence is itself Gaussian. The mean and covariance is given by</p>
<script type="math/tex; mode=display">
\mathbb{E}[y] = \phi(\mathbf x)^T\mathbb{E}(\mathbf w)=\phi(\mathbf x)^T\mathbf{m}_N,\\
\text{cov}[y,y']=\mathbb E [(y-\mathbb{E}[y])(y'-\mathbb{E}[y'])] =\phi(\mathbf x)^T\mathbf{S}_N\phi(\mathbf x^\prime),</script><p>We already have </p>
<script type="math/tex; mode=display">
\mathbf m_N=\beta\mathbf S_N\Phi^T\mathbf t\\
\mathbf S_N^{-1}=\alpha I+\beta\Phi^T\Phi</script><p>therefore,</p>
<script type="math/tex; mode=display">
\mathbb E[y]=\beta\phi(\mathbf x)^T\mathbf S_N\Phi^T\mathbf t \\
\text{var}[y]=\phi(\mathbf x)^T\mathbf S_N\phi(\mathbf x)</script><p>The mean and variance can be rewritten as following (though I didn’t try)</p>
<script type="math/tex; mode=display">
\mathbb E[y]=\phi(\mathbf x)^T\Sigma_p\Phi(K+\beta^{-1}I)^{-1}\mathbf t\\
\text{var}[y]=\phi(\mathbf x)^T\Sigma_p\phi(\mathbf x)-\phi(\mathbf x)^T\Sigma_p\Phi(K+\beta^{-1}I)^{-1}\Phi^T\Sigma_p\phi(\mathbf x)</script><p>where $\Sigma_p=\alpha^{-1} I$ and $K=\Phi^T \Sigma_p\Phi$.</p>
<p>Define $k(\mathbf x, \mathbf x^{\prime})=\phi(\mathbf x)^T\Sigma_p\phi(\mathbf x^{\prime})$, we can easily see Bayesian linear regression is equivalent to a Gaussian Process model, whose mean and variance of the predictive distribution are</p>
<script type="math/tex; mode=display">
\pmb{\mu}=k(\mathbf x, \mathbf X)^T(K+\beta^{-1}I)^{-1}\mathbf t\\
\Sigma=k(\mathbf x, \mathbf x)-k(\mathbf x, \mathbf X)^T (K+\beta^{-1}I)^{-1}k(\mathbf x, \mathbf X)</script><h2 id=""><a href="#" class="headerlink" title=""></a><!--4. The Evidence Approximation--></h2><!--marginalisation over hyperparameters-->
<!--laplace approximation-->
<!--EM-->
<!--log marginal likelihood-->
<p>(Finish writing on 2018-05-23 T^T)</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>​    [1]. Christopher M. Bishop (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</p>
<p>​    [2]. Rasmussen, C. E., &amp; Williams, C. K. (2006). <em>Gaussian process for machine learning</em>. MIT press.</p>
<p>​    [3]. Robert, C. (2014). <em>Machine learning, a probabilistic perspective.</em></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/algorithms/" rel="tag"># algorithms</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/01/EP/" rel="next" title="Expectation Propagation">
                <i class="fa fa-chevron-left"></i> Expectation Propagation
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/16/FG/" rel="prev" title="The sum-product algorithm">
                The sum-product algorithm <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/duola.jpg"
                alt="lemelondeau" />
            
              <p class="site-author-name" itemprop="name">lemelondeau</p>
              <p class="site-description motion-element" itemprop="description">J'aime le melon d'eau.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/lemelondeau" target="_blank" title="github">
                    
                      <i class="fa fa-fw fa-globe"></i>github</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Linear-Basis-Function-Models"><span class="nav-text">1. Linear Basis Function Models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-Model-Formalisation"><span class="nav-text">1.1 Model Formalisation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-Model-Fitting"><span class="nav-text">1.2 Model Fitting</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Bayesian-Linear-Regression"><span class="nav-text">2. Bayesian Linear Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Posterior-Distribution-of-Parameter"><span class="nav-text">2.1 Posterior Distribution of Parameter</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Predictive-Distribution"><span class="nav-text">2.2 Predictive Distribution</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Relation-with-Gaussian-Process"><span class="nav-text">3. Relation with Gaussian Process</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-text">References</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lemelondeau</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  

    
      <script id="dsq-count-scr" src="https://lemelondeau.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://lemelondeau.github.io/2018/05/10/BLR/';
          this.page.identifier = '2018/05/10/BLR/';
          this.page.title = 'Bayesian Linear Regression and Gaussian Process';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://lemelondeau.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
